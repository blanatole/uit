import re
import argparse
import pandas as pd
import torch
from tqdm import tqdm
from transformers import AutoModelForCausalLM, AutoTokenizer

LABELS = ["no", "intrinsic", "extrinsic"]
# Si·∫øt regex: ch·ªâ b·∫Øt ·ªü ƒë·∫ßu chu·ªói, c√≥ th·ªÉ c√≥ "label:"
PAT = re.compile(r"^\s*(?:label\s*:\s*)?(no|intrinsic|extrinsic)\b", re.IGNORECASE)

ROLE_SYS = {
    "literalist": (
        "Vai tr√≤: B√ÅM VƒÇN B·∫¢N. B·∫°n c·∫©n th·∫≠n, ch√≠nh x√°c, ch·ªâ d·ª±a v√†o th√¥ng tin c√≥ trong NG·ªÆ C·∫¢NH.\n"
        "N·∫øu c√¢u tr·∫£ l·ªùi KH√îNG c√≥ trong ng·ªØ c·∫£nh ‚Üí extrinsic\n"
        "N·∫øu c√¢u tr·∫£ l·ªùi SAI so v·ªõi ng·ªØ c·∫£nh ‚Üí intrinsic\n"
        "N·∫øu c√¢u tr·∫£ l·ªùi ƒê√öNG v√† c√≥ trong ng·ªØ c·∫£nh ‚Üí no"
    ),
    "skeptic": (
        "Vai tr√≤: HO√ÄI NGHI. B·∫°n t√¨m ki·∫øm l·ªói, m√¢u thu·∫´n, thi·∫øu ch·ª©ng c·ª©.\n"
        "N·∫øu th·∫•y th√¥ng tin KH√îNG c√≥ trong ng·ªØ c·∫£nh ‚Üí extrinsic\n"
        "N·∫øu th·∫•y th√¥ng tin SAI so v·ªõi ng·ªØ c·∫£nh ‚Üí intrinsic\n"
        "N·∫øu th·∫•y th√¥ng tin ƒê√öNG v√† c√≥ ch·ª©ng c·ª© ‚Üí no"
    ),
    "verifier": (
        "Vai tr√≤: TH·∫®M ƒê·ªäNH. B·∫°n ki·ªÉm tra t·ª´ng m·ªánh ƒë·ªÅ m·ªôt c√°ch kh√°ch quan.\n"
        "ƒê·ªëi chi·∫øu t·ª´ng c√¢u v·ªõi NG·ªÆ C·∫¢NH:\n"
        "- C√≥ trong ng·ªØ c·∫£nh v√† ƒë√∫ng ‚Üí no\n"
        "- C√≥ trong ng·ªØ c·∫£nh nh∆∞ng sai ‚Üí intrinsic\n"
        "- Kh√¥ng c√≥ trong ng·ªØ c·∫£nh ‚Üí extrinsic"
    ),
}

JUDGE_SYS = (
    "B·∫°n l√† TR·ªåNG T√ÄI cu·ªëi c√πng. Nh·∫≠n votes t·ª´ 3 vai tr√≤ chuy√™n gia.\n\n"
    "QUY T·∫ÆC QUY·∫æT ƒê·ªäNH:\n"
    "1. N·∫øu 2+ vai tr√≤ vote 'no' ‚Üí no (c√¢u tr·∫£ l·ªùi ƒë√∫ng)\n"
    "2. N·∫øu 2+ vai tr√≤ vote 'intrinsic' ‚Üí intrinsic (sai so v·ªõi ng·ªØ c·∫£nh)\n"
    "3. N·∫øu 2+ vai tr√≤ vote 'extrinsic' ‚Üí extrinsic (th√™m th√¥ng tin kh√¥ng c√≥)\n"
    "4. N·∫øu h√≤a (1-1-1) ‚Üí ch·ªçn 'no' (∆∞u ti√™n an to√†n)\n\n"
    "Ch·ªâ in 1 t·ª´ duy nh·∫•t: no ho·∫∑c intrinsic ho·∫∑c extrinsic."
)


def build_case(row: pd.Series) -> str:
    return (
        f"NG·ªÆ C·∫¢NH:\n{row['context']}\n\n"
        f"C√ÇU H·ªéI:\n{row['prompt']}\n\n"
        f"C√ÇU TR·∫¢ L·ªúI C·ª¶A TR·ª¢ L√ù:\n{row['response']}\n"
    )


def parse_label(text: str):
    m = PAT.search(text)
    return m.group(1).lower() if m else None


@torch.inference_mode()
def debate_predict_csv(input_csv: str, output_csv: str, model_dir: str, rounds: int = 1):
    tok = AutoTokenizer.from_pretrained(model_dir, use_fast=True)
    model = AutoModelForCausalLM.from_pretrained(model_dir, device_map="auto", torch_dtype=torch.bfloat16)

    # ƒê·ªçc JSONL thay v√¨ CSV
    df = pd.read_json(input_csv, lines=True)

    ids = []
    preds = []

    # Test mode: ch·ªâ d√πng 20 m·∫´u ƒë·∫ßu ƒë·ªÉ ki·ªÉm tra
    df_test = df.head(20)
    print(f"üß™ Test mode: Using only {len(df_test)} samples")
    
    pbar = tqdm(range(len(df_test)), desc="DebateCSV", dynamic_ncols=True)
    for i in pbar:
        row = df_test.iloc[i]
        ids.append(row["id"])
        case = build_case(row)

        votes = []
        for _ in range(rounds):
            for role in ["literalist", "skeptic", "verifier"]:
                msgs = [
                    {"role": "user", "content": ROLE_SYS[role] + "\n\n" +
                     "NHI·ªÜM V·ª§: ƒê·ªçc k·ªπ ng·ªØ c·∫£nh v√† c√¢u tr·∫£ l·ªùi, sau ƒë√≥:\n"
                     "1. Ch·ªçn 1 trong 3 nh√£n: no, intrinsic, extrinsic\n"
                     "2. Vi·∫øt theo format: label: <nh√£n>\n"
                     "3. Gi·∫£i th√≠ch ng·∫Øn g·ªçn l√Ω do (1-2 c√¢u)\n\n" + case}
                ]
                text = tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)
                inputs = tok(text, return_tensors="pt").to(model.device)
                out = model.generate(
                    **inputs, 
                    max_new_tokens=64, 
                    do_sample=False, 
                    temperature=0.1,
                    eos_token_id=tok.eos_token_id,
                    pad_token_id=tok.eos_token_id
                )
                dec = tok.decode(out[0][inputs["input_ids"].shape[1]:], skip_special_tokens=True)
                print(f"  {role}: {dec[:100]}...")  # Log ƒë·ªÉ debug
                y = parse_label(dec)
                if y:
                    votes.append(y)

        maj = max(set(votes), key=votes.count) if votes else "no"

        judge_msgs = [
            {"role": "user", "content": JUDGE_SYS + "\n\n" +
             f"K·∫æT QU·∫¢ VOTES:\n"
             f"- Literalist: {votes[0] if len(votes) > 0 else 'N/A'}\n"
             f"- Skeptic: {votes[1] if len(votes) > 1 else 'N/A'}\n"
             f"- Verifier: {votes[2] if len(votes) > 2 else 'N/A'}\n\n"
             f"QUY·∫æT ƒê·ªäNH CU·ªêI C√ôNG: Ch·ªâ in 1 t·ª´ duy nh·∫•t: no ho·∫∑c intrinsic ho·∫∑c extrinsic."}
        ]
        jtext = tok.apply_chat_template(judge_msgs, tokenize=False, add_generation_prompt=True)
        jinputs = tok(jtext, return_tensors="pt").to(model.device)
        jout = model.generate(
            **jinputs, 
            max_new_tokens=3, 
            do_sample=False, 
            temperature=0.1,
            eos_token_id=tok.eos_token_id,
            pad_token_id=tok.eos_token_id
        )
        jdec = tok.decode(jout[0][jinputs["input_ids"].shape[1]:], skip_special_tokens=True).strip()
        print(f"  judge: {jdec[:100]}...")  # Log ƒë·ªÉ debug
        final = parse_label(jdec) or maj

        if final not in LABELS:
            final = "no"
        preds.append(final)

        print(f"  votes: {votes}, maj: {maj}, final: {final}")  # Log ƒë·ªÉ debug
        if votes:
            pbar.set_postfix({"maj": maj, "votes": {l: votes.count(l) for l in set(votes)}})

    pd.DataFrame({"id": ids, "predict_label": preds}).to_csv(output_csv, index=False)
    print(f"‚úÖ Wrote predictions to {output_csv} ({len(ids)} rows)")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--ckpt", required=True)
    parser.add_argument("--input_csv", required=True)
    parser.add_argument("--output_csv", required=True)
    parser.add_argument("--rounds", type=int, default=1)
    args = parser.parse_args()

    debate_predict_csv(args.input_csv, args.output_csv, args.ckpt, rounds=args.rounds)


